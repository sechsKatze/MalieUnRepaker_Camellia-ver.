# Malie Engine Repacker (malierepack.py)
# 
# This repacker was written from scratch to reconstruct Malie engine `.dat` archives.
# While the repack logic itself is original, the Camellia encryption and some structural
# behaviors were referenced from the GARbro project (https://github.com/morkt/GARbro).
#
# Special thanks to morkt (original GARbro author) and Neidhardt
#
# Licensed under the MIT License.

# .lib, .dat ë¦¬íŒ¨í‚¹ ë¡œì§ê³¼ Camellia ì—°ê³„ ì•”í˜¸í™” ë¡œì§ì€ ì›ë³¸ì— ì—†ìœ¼ë©° ë”°ë¡œ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤.

import os, io, struct
import logging
from io import BytesIO
from collections import defaultdict
from functools import lru_cache
from malie.camellia import Camellia

        
#.lib ë¦¬íŒ©ìš© (ë¹„ì•”í˜¸í™”) - ì›ë³¸ ì½”ë“œ(garbro)ì— ì—†ìŒ
# .lib í™•ì¥ìë¥¼ ê°€ì§„ ë§ë¦¬ ì—”ì§„ ê²Œì„ì´ ì—†ì–´ í…ŒìŠ¤íŠ¸ë¥¼ ëª»í•´ ì£¼ì„ ì²˜ë¦¬. ì´ë¡ ìƒ ê°€ëŠ¥í•˜ë‹¤ëŠ” ì •ë„.
# class LibWriter:
#     def __init__(self):
#         self.entries = []

#     def add_entry(self, name: str, data: bytes):
#         encoded_name = name.encode("cp932")
#         if len(encoded_name) > 36:
#             raise ValueError(f"[lib] íŒŒì¼ëª… '{name}' ì´(ê°€) ë„ˆë¬´ ê¹ë‹ˆë‹¤ (ìµœëŒ€ 36 bytes)")
#         self.entries.append((name.replace("\\", "/"), data))

#     def write(self, output_path: str):
#         with open(output_path, "wb") as f:
#             self._write_archive(f)

#     # í—¤ë” ì‘ì„±
#     def _write_archive(self, f: io.BufferedWriter):
#         # Header: 'LIB\x00' + reserved 12 bytes
#         f.write(b'LIB\x00')
#         f.write(b'\x00' * 4)  # reserved
#         f.write(struct.pack("<H", len(self.entries)))  # count: 2 bytes
#         f.write(b'\x00' * 6)  # reserved

#         # Index table start offset
#         index_offset = f.tell()
#         f.seek(0x30 * len(self.entries), io.SEEK_CUR)

#         # File data write phase
#         data_offset = f.tell()
#         index_entries = []

#         for name, data in self.entries:
#             entry_offset = f.tell()
#             f.write(data)
#             rel_offset = entry_offset - data_offset
#             entry_size = len(data)
#             index_entries.append((name, entry_size, rel_offset))

#         # Write index table
#         f.seek(index_offset)
#         for name, size, rel_offset in index_entries:
#             name_bytes = name.encode("cp932")
#             name_bytes += b'\x00' * (36 - len(name_bytes))
#             f.write(name_bytes)
#             f.write(struct.pack("<II", size, rel_offset))
#             f.write(b'\x00' * 8)  # reserved (0x2C ~ 0x2F + 0x30 total)

# í‰ë¬¸ .dat ë¦¬íŒ© ì½”ë“œ
# ë§ë¦¬ ì—”ì§„ì€ ì•”í˜¸í™”ê°€ ê±¸ë¦¬ì§€ ì•Šì€ í‰ë¬¸ ë¦¬íŒ©ë„ ê²Œì„ ì¸ì‹ì´ ë˜ê¸° ë•Œë¬¸ì— ì•”í˜¸í™” ë¡œì§ì„ ìƒëµí•¨.
# ì—”ì§„ì˜ íŒŒì¼ ë¦¬ì „ê³¼ ì¸ë±ìŠ¤ í…Œì´ë¸”ì˜ ê³„ì¸µ ë¬¸ì œë¡œ ì¸ë±ìŠ¤ í…Œì´ë¸” ìˆœì„œì™€ íŒŒì¼ ì‘ì„± ìˆœì„œëŠ” jsonì˜ entry_indexì™€ order ì¹´í”¼ê°€ í•„ìˆ˜.
class DatWriterplain:
    def __init__(self, entry_list=None, base_dir=None, meta_dict=None):
        if entry_list is None:
            entry_list = []

        self.entries = entry_list
        self.base_dir = base_dir
        self.output = bytearray()
        self.plain_data = None
        self.meta_dict = meta_dict or {}  # â† meta_dict ì¶”ê°€
        self.write = self.Writer(self)
        self.save = self.Save(self)
        self.offset_table_pos = None

        # âœ… ì˜¤í”„ì…‹ ëŒ€ìƒ: ì‹¤ì œ íŒŒì¼ë§Œ (ë””ë ‰í† ë¦¬/ë£¨íŠ¸ ì œì™¸)
        self.offset_entries = [
            e for e in entry_list
            if not e.get("is_dir", False)
        ]

        # âœ… ì¸ë±ìŠ¤ ëŒ€ìƒ: ë£¨íŠ¸ ë””ë ‰í† ë¦¬ ì œì™¸ ì „ì²´ entry
        self.index_entries = [
            e for e in entry_list
            if e.get("is_dir", False) or not e.get("is_dir", False)
        ]

        # âœ… ë””ë ‰í† ë¦¬ ëª©ë¡: nameì´ Noneì´ë©´ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¡œ ì·¨ê¸‰
        self.folders = [
            e for e in entry_list
            if e.get("is_dir", False)
        ]

        # âœ… name í•„ë“œ ë³´ì • (ëˆ„ë½ëœ ê²½ìš°)
        for e in self.entries:
            if "name" not in e or e["name"] is None:
                arc = e.get("arc_path") or ""
                e["name"] = os.path.basename(arc.rstrip("/"))

        
    def add_entry(self, arc_path: str, src_path: str, is_dummy: bool = False):
        entry = {
            "arc_path": arc_path,
            "src_path": src_path,
            "name": os.path.basename(arc_path.rstrip("/")), 
        }

        full_path = os.path.normpath(src_path)
        is_dir = os.path.isdir(full_path)
        entry["is_dir"] = is_dir

        # â”€â”€â”€ size / data ì²˜ë¦¬ â”€â”€â”€
        if is_dir:
            entry["size"] = None
            entry["data"] = b""
            entry["type_val"] = 0x00
            entry["extension"] = ""
        elif os.path.isfile(full_path):
            with open(full_path, "rb") as f:
                data = f.read()
            entry["size"] = len(data)
            entry["data"] = data
            entry["offset"] = None
            entry["type_val"] = 0x10000
            entry["extension"] = os.path.splitext(arc_path)[-1].lower()
        else:
            logging.warning(f"[add_entry] íŒŒì¼ ë˜ëŠ” ë””ë ‰í† ë¦¬ ì•„ë‹˜: {src_path}")
            return

        # í›„ì† ì²˜ë¦¬ë¥¼ ìœ„í•œ ë³´ì¡° í•„ë“œ ì´ˆê¸°í™” (index ê´€ë ¨)
        # entry["entry_index"] = None
        entry["offset_index"] = None
        entry["offset"] = None
        entry["order"] = -1
        
        self.entries.append(entry)
    
    def add_auto(self, input_dir: str, arc_path: str, root_dir: str = None):
        if root_dir is None:
            root_dir = input_dir  # ìµœì´ˆ í˜¸ì¶œ ì‹œ root_dir ê³ ì •

        full_path = os.path.normpath(os.path.join(input_dir, arc_path))
        rel_arc_path = os.path.relpath(full_path, root_dir).replace("\\", "/")

        if rel_arc_path in ("", ".", "./"):
            rel_arc_path = ""

        # â”€â”€â”€â”€â”€â”€ ë””ë ‰í† ë¦¬ ì²˜ë¦¬ â”€â”€â”€â”€â”€â”€
        if os.path.isdir(full_path):
            if not rel_arc_path.endswith("/") and rel_arc_path != "":
                rel_arc_path += "/"

            # âœ… ë£¨íŠ¸ ë””ë ‰í† ë¦¬ëŠ” ë“±ë¡í•˜ì§€ ì•ŠìŒ (arc_path == "")
            if rel_arc_path != "":
                entry = {
                    "arc_path": rel_arc_path,
                    "src_path": full_path,
                    "name": os.path.basename(rel_arc_path.rstrip("/")), 
                    "is_dir": True,
                    "type_val": 0,
                    "size": 0,
                    "data": b"",
                    "is_dummy": False,
                    "entry_index": None,
                    "offset_index": None,
                    "offset": None,
                    "order": -1,
                    "extension": "",
                }
                self.entries.append(entry)

            # ì¬ê·€ì ìœ¼ë¡œ í•˜ìœ„ í•­ëª© ì¶”ê°€
            for child in sorted(os.listdir(full_path)):
                self.add_auto(full_path, child, root_dir=root_dir)

        # â”€â”€â”€â”€â”€â”€ íŒŒì¼ ì²˜ë¦¬ â”€â”€â”€â”€â”€â”€
        elif os.path.isfile(full_path):
            self.add_entry(rel_arc_path, full_path)

        # â”€â”€â”€â”€â”€â”€ ê·¸ ì™¸ (ì—†ê±°ë‚˜ ì˜ëª»ëœ ê²½ë¡œ) â”€â”€â”€â”€â”€â”€
        else:
            logging.warning(f"[add_auto] íŒŒì¼/ë””ë ‰í† ë¦¬ ì—†ìŒ: {full_path}")

    def sorted_entries(self):
        entries = list(self.entries)
        entries.sort(key=lambda e: e["entry_index"] if isinstance(e.get("entry_index"), int) else 99999)
        return entries
     
    # ìˆ˜ì •ëœ finalize_folders()
    def finalize_folders(self):
        @lru_cache(maxsize=None)
        def normalize_dir(path: str) -> str:
            path = os.path.normpath(path).replace("\\", "/")
            if path in ("", ".", "./"):
                return ""
            return path.rstrip("/") + "/"

        root_dir_name = self.base_dir.rstrip("/\\").split(os.sep)[-1]
        normalized_root_dir = normalize_dir(root_dir_name)
        logging.debug(f"[finalize_folders] ì‚­ì œ ëŒ€ìƒ ìµœìƒìœ„ í´ë” ì´ë¦„ (ì •ê·œí™”): '{normalized_root_dir}'")

        dir_set = set()
        for entry in self.entries:
            arc_path = entry.get("arc_path")
            if not arc_path or (entry.get("is_dir") and not arc_path.strip("/")):
                continue
            folder = normalize_dir(os.path.dirname(arc_path))
            while folder:
                dir_set.add(folder)
                parent = normalize_dir(os.path.dirname(folder.rstrip("/")))
                if parent == folder or parent == "":
                    break
                folder = parent

        has_root = any(
            e.get("is_dir") and (e.get("arc_path") in (None, "", "./", "/"))
            for e in self.entries
        )

        if not has_root:
            subdir_count = sum(
                1 for e in self.entries if e.get("is_dir") and e.get("arc_path")
            )
            self.entries.insert(0, {
                "arc_path": None,
                "name": None,
                "entry_index": 0,
                "offset_index": None,
                "offset": 0,
                "size": subdir_count,
                "is_dir": True,
                "order": None,
                "extension": "",
                "src_path": "__root__",
                "type_val": 0x00,
                "flags": 0x04 if subdir_count > 0 else 0x05,
                "data": b"",
            })

        seen = set()
        unique_entries = []
        for e in self.entries:
            ident = (e.get("arc_path"), e.get("is_dir", False))
            if ident not in seen:
                seen.add(ident)
                unique_entries.append(e)
            else:
                logging.debug(f"[finalize_folders] ì¤‘ë³µ ì œê±°ë¨: {ident}")
        self.entries = unique_entries

        child_count = defaultdict(int)
        for e in self.entries:
            arc = normalize_dir(e.get("arc_path") or "")
            parent = normalize_dir(os.path.dirname(arc.rstrip("/")))
            child_count[parent] += 1

        self.index_entries = self.entries.copy()

        def sort_entries_dfs(entries, normalize_dir):
            entry_map = {
                normalize_dir(e.get("arc_path")): e
                for e in entries if e.get("arc_path") is not None
            }
            children_map = defaultdict(list)
            for e in entries:
                arc = normalize_dir(e.get("arc_path"))
                parent = normalize_dir(os.path.dirname(arc.rstrip("/"))) if arc else ""
                children_map[parent].append(e)

            result = []

            def dfs(current=""):
                children = children_map.get(current, [])
                dirs = [e for e in children if e.get("is_dir", False)]
                files = [e for e in children if not e.get("is_dir", False)]
                dirs.sort(key=lambda e: e.get("arc_path"))
                files.sort(key=lambda e: e.get("arc_path"))
                result.extend(dirs)
                result.extend(files)
                for d in dirs:
                    dfs(normalize_dir(d.get("arc_path")))

            dfs()
            return result, entry_map

        # ì •ë ¬ëœ ì—”íŠ¸ë¦¬ë¡œ ë®ì–´ì“°ê¸°
        sorted_entries, self.index_map = sort_entries_dfs(
            [e for e in self.index_entries if e.get("entry_index") != 0 and e.get("arc_path") not in (None, "", "./", "/")],
            normalize_dir
        )
        self.index_entries = [e for e in self.entries if e.get("entry_index") == 0] + sorted_entries

        # type_val, flags, sizeëŠ” ë©”íƒ€ ê¸°ë°˜ìœ¼ë¡œ ë®ì–´ì“°ê¸° (entry_metadata_manager ì‚¬ìš© ì‹œ ë³´ì¥ë¨)
        for entry in self.index_entries:
            if entry.get("is_dir", False):
                arc_path = normalize_dir(entry.get("arc_path") or "")
                entry["size"] = child_count.get(arc_path, 0)
                entry["flags"] = 0x04 if entry["size"] > 0 else 0x05
                entry["type_val"] = 0x00000
            else:
                # sizeëŠ” ë°˜ë“œì‹œ ë©”íƒ€ì—ì„œ ë³µì‚¬í•œ ê°’ì´ì–´ì•¼ í•¨. ì—¬ê¸°ì„œ len(data)ë¡œ ë®ìœ¼ë©´ ì•ˆ ë¨!
                entry.setdefault("type_val", 0x10000)
                entry.setdefault("flags", 0x00)

        # offset_entries
        self.offset_entries = [e for e in self.index_entries if not e.get("is_dir", False)]
        self.offset_entries.sort(key=lambda e: e.get("entry_index", 0))
        for i, entry in enumerate(self.offset_entries):
            entry["offset_index"] = i

        logging.debug("[finalize_folders] ì™„ë£Œ")

    class Writer:
        def __init__(self, outer):
            self.outer = outer
            self.entries = outer.entries
            self.base_dir = outer.base_dir
            self.ALIGN_FILE_START = 0x1000

        # í—¤ë” ì‘ì„±
        def write_header(self):
            total_entry_count = len(self.outer.entries)
            offset_entry_count = len([e for e in self.outer.entries if not e.get("is_dir", False)])

            # ë£¨íŠ¸ ë””ë ‰í† ë¦¬ ìƒì„± ì—¬ë¶€ í™•ì¸ (finalize_foldersì—ì„œ ì´ë¯¸ ì‚½ì…ëœ ìƒíƒœ)
            has_root = any(
                e.get("is_dir") and (e.get("arc_path") is None or e.get("arc_path") == "")
                for e in self.outer.entries
            )

            # finalize_foldersì—ì„œ ìƒì„± ëœ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ ì¹´ìš´íŠ¸ í›„ ì •ë³´ë¥¼ ê¸°ë¡í•¨.
            dir_root_count = 1 if has_root else 0
            # ê³„ì¸µ ë””ë ‰í† ë¦¬ëŠ” ì œì™¸. root ë””ë ‰í† ë¦¬ ì•ˆì˜ ë””ë ‰í† ë¦¬ë§Œ ì¹´ìš´íŠ¸
            subdirs = set()
            for e in self.outer.entries:
                if not e.get("is_dir", False):
                    continue
                arc = e.get("arc_path")
                if not arc or arc in ("", "./", "/"):
                    continue
                norm = arc.rstrip("/")
                if "/" not in norm:
                    subdirs.add(norm)

            subdir_count = len(subdirs)

            mystery_padding = b'\x00' * 8
            reserved = b'\x00' * 20

            parts = [
                b'LIBP',
                struct.pack('<I', total_entry_count),
                struct.pack('<I', offset_entry_count),
                mystery_padding,
                reserved,
                struct.pack('<I', dir_root_count),
                struct.pack('<I', subdir_count),
            ]

            header = b''.join(parts)
            assert len(header) == 0x30, f"í—¤ë” ê¸¸ì´ ë¶ˆì¼ì¹˜: {len(header)}"
            self.outer.output += header

            logging.info(f"[write] í—¤ë” ì‘ì„± ì™„ë£Œ (ì´ {total_entry_count}, íŒŒì¼ {offset_entry_count}, ë””ë ‰í† ë¦¬ {subdir_count})")
            
        # íŒŒì¼ ì¸ë±ìŠ¤ í…Œì´ë¸” ì‘ì„±
        # ë£¨íŠ¸ ë””ë ‰í† ë¦¬ëŠ” ì œì™¸. jsonì˜ entry_index ìˆœë²ˆ ë°˜ì˜, ë””ë ‰í† ë¦¬ ì •ë³´ ë˜í•œ json ë°˜ì˜.
        # 20ë°”ì´íŠ¸ í•œê³„ë¡œ 21ë°”ì´íŠ¸ê°€ ë„˜ì–´ê°€ëŠ” íŒŒì¼ëª…ì€ í—¥ìŠ¤ ì—ë””í„°ë¡œ ìˆ˜ì • í•„ìˆ˜. (íŒŒì¼ëª…ì„ ìˆ˜ì •í•˜ëŠ” ë°©ë²•ë„ ìˆìœ¼ë‚˜ ì—°ê³„ íŒŒì¼ë“¤ë„ ê°™ì´ ìˆ˜ì •í•´ì•¼ í•¨.)
        # ìˆœì„œëŠ” ê° .datë§ˆë‹¤ ë‹¤ë¦„. 
        def write_index_table(self):
            def encode_name(name: str) -> bytes:
                raw = name.encode("cp932", "ignore").split(b'\x00')[0][:20]
                return raw.ljust(20, b'\x00')

            index_table = bytearray()
            count = 0

            entries = sorted(
                self.outer.index_entries,
                key=lambda e: e.get("entry_index", -1) if isinstance(e.get("entry_index"), int) else 99999
            )
            for i, e in enumerate(entries):
                logging.debug(f"[write_index_table] #{i} {e.get('arc_path')} (entry_index={e.get('entry_index')})")

            for e in entries:
                arc_path = e.get("arc_path") or ""
                is_dir = bool(e.get("is_dir", False))

                if is_dir and arc_path.strip("/").strip() == "":
                    logging.debug(f"[write_index_table] ë£¨íŠ¸ ë””ë ‰í† ë¦¬ ì œì™¸: {e}")
                    continue

                arc_name = os.path.basename(arc_path.rstrip("/"))
                name_bytes = encode_name(arc_name)
                assert len(name_bytes) == 20, f"name_bytes ê¸¸ì´ ì˜¤ë¥˜: {arc_name} â†’ {len(name_bytes)}"

                type_val = e["type_val"]
                size = e["size"]
                entry_bytes = bytearray()
                entry_bytes += name_bytes                          # 0x00â€“0x13
                entry_bytes += struct.pack("<I", type_val)         # 0x14â€“0x17

                # âœ… 0x18â€“0x1B ìœ„ì¹˜ì— ë„£ì„ ê°’
                raw_0x18 = None

                if is_dir:
                    tail_raw_hex = e.get("index_tail_raw")
                    assert tail_raw_hex, f"ë””ë ‰í† ë¦¬ì¸ë° index_tail_raw ì—†ìŒ: {arc_path}"
                    raw_0x18 = bytes.fromhex(tail_raw_hex)
                else:
                    raw_0x18 = struct.pack("<I", e["offset_index"])

                entry_bytes += raw_0x18                            # 0x18â€“0x1B
                entry_bytes += struct.pack("<I", size)             # 0x1Câ€“0x1F

                assert len(entry_bytes) == 0x20, f"entry í¬ê¸° ì˜¤ë¥˜: {arc_path}"
                index_table += entry_bytes
                count += 1

            self.outer.output += index_table
            logging.info(f"[write_index_table] ì¸ë±ìŠ¤ í…Œì´ë¸” ì‘ì„± ì™„ë£Œ (ì—”íŠ¸ë¦¬ ìˆ˜: {count})")
        
        # ë² ì´ìŠ¤ ì˜¤í”„ì…‹ ê³„ì‚° (íŒŒì¼ ë°ì´í„° ì‘ì„±ê³¼ ì—°ê³„)
        def calculate_base_offset(self):
            ALIGN_BASE = 0x1000  # âœ… íŒŒì¼ ë°ì´í„° ì •ë ¬ ë‹¨ìœ„

            entry_count = len(self.outer.entries)
            file_count = len([e for e in self.outer.entries if not e.get("is_dir", False)])

            index_size = entry_count * 0x20
            offset_table_size = file_count * 4

            raw_base = 0x10 + index_size + offset_table_size
            self.outer.base_offset = (raw_base + ALIGN_BASE - 1) & ~(ALIGN_BASE - 1)
            
        # ì˜¤í”„ì…‹(ì˜¤í”„ì…‹ í…Œì´ë¸”, ë² ì´ìŠ¤ ì˜¤í”„ì…‹) ê³„ì‚°ê³¼ ì •ë ¬
        def prepare_offsets(self):
            all_entries = self.outer.offset_entries
            offset_entries = [e for e in all_entries if not e.get("is_dir", False)]
            self.offset_table = [0] * len(offset_entries)

            for entry in offset_entries:
                write_offset = entry.get("write_offset")
                if write_offset is None:
                    raise ValueError(f"write_offset ëˆ„ë½: {entry.get('arc_path')}")

                offset_val = (write_offset - self.outer.base_offset) >> 10
                self.offset_table[entry["offset_index"]] = offset_val

            logging.info(f"[prepare_offsets] ì˜¤í”„ì…‹ ê³„ì‚° ì™„ë£Œ (ì´ íŒŒì¼ ìˆ˜: {len(offset_entries)})")
            
        # ì˜¤í”„ì…‹ í…Œì´ë¸” ì‘ì„± (prepare_offsetsì—ì„œ ë°ì´í„°ë¥¼ ë°›ìŒ)
        def write_offset_table(self):
            offset_pos = 0x10 + 0x20 * len(self.outer.entries)

            # offset_table â†’ ë°”ì´íŠ¸ ë³€í™˜
            table_bytes = bytearray()
            for val in self.offset_table:
                table_bytes += struct.pack("<I", val)

            if isinstance(self.outer.output, bytearray):
                if len(self.outer.output) < offset_pos + len(table_bytes):
                    self.outer.output += bytearray(offset_pos + len(table_bytes) - len(self.outer.output))
                self.outer.output[offset_pos:offset_pos + len(table_bytes)] = table_bytes
            else:
                self.outer.output.seek(offset_pos)
                self.outer.output.write(table_bytes)

            logging.info(f"[write_offset_table] ì˜¤í”„ì…‹ í…Œì´ë¸” ì‘ì„± ì™„ë£Œ (ì´ {len(self.offset_table)}ê°œ)")

        # íŒŒì¼ ë°ì´í„° ì‘ì„± 
        # íŒŒì¼ ë°ì´í„° ìˆœì„œê°€ ì—‰ë§ì´ê¸°ì— ë©”íƒ€ë°ì´í„°.json ì°¸ì¡° ì¹´í”¼ í•„ìˆ˜.
        def write_data(self):
            # ë‚´ë¶€ ì •ë ¬ í•¨ìˆ˜ ì •ì˜
            def align_inner(val):
                # íŒŒì¼ ê°„ ìµœì†Œ ê°„ê²© ì •ë ¬ (0x400)
                return (val + 0x3FF) & ~0x3FF

            def align_block(val):
                # í° ë¸”ë¡ ì •ë ¬ (0x1000)
                return (val + 0xFFF) & ~0xFFF

            entries = sorted(
                [e for e in self.outer.entries if not e.get("is_dir", False)],
                key=lambda e: e.get("order", -1)
            )

            cursor = self.outer.base_offset

            for idx, entry in enumerate(entries):
                arc_path = entry["arc_path"]
                size = int(entry["size"], 16) if isinstance(entry["size"], str) else entry["size"]
                data = entry["data"]

                # ğŸ›  ë‘ ë‹¨ê³„ ì •ë ¬ ì ìš©
                offset = align_inner(cursor)
                if (offset // 0x1000) != (cursor // 0x1000):
                    offset = align_block(cursor)

                end_offset = offset + size
                entry["write_offset"] = offset

                # write
                if len(self.outer.output) < end_offset:
                    self.outer.output += bytearray(end_offset - len(self.outer.output))
                self.outer.output[offset:end_offset] = data

                # log
                if getattr(self.outer, "debug", True):
                    logging.debug(
                        f"[write_data] #{idx:04d} | {arc_path}"
                        f"\n    write_offset=0x{offset:X}, size=0x{size:X}, end=0x{end_offset:X}"
                        f"\n    new_output_len=0x{len(self.outer.output):X}"
                    )

                cursor = end_offset


    # ë¦¬íŒ© í›„ .dat ì €ì¥
    class Save:
        def __init__(self, outer):
            self.outer = outer

        def to_file(self, path: str):
            with open(path, "wb") as f:
                f.write(self.outer.output)
                print(f"[ì™„ë£Œ] í‰ë¬¸ DAT ë¦¬íŒ© â†’ {path}")



# # camellia ì•”í˜¸í™” ë¡œì§ - ì›ë³¸ ì½”ë“œì— ì—†ìŒ, pythonì€ ìˆœì„œ ë¬¸ì œë¡œ ìœ„ë¡œ ì˜®ê¹€.
# def write_encrypted(f, encryptor, offset: int, data: bytes | bytearray) -> int:
#     if not data:
#         return 0

#     # â‘  block_offset, current_offset, offset_pad ê³„ì‚°
#     block_offset = offset >> 4                 # 16ë°”ì´íŠ¸ ë‹¨ìœ„ ë¸”ë¡ ì˜¤í”„ì…‹
#     current_offset = block_offset << 4         # ë¸”ë¡ ì‹œì‘ ì˜¤í”„ì…‹(16ë°°ìˆ˜)
#     offset_pad = offset - current_offset       # ì‹¤ì œ offset ëŒ€ë¹„ íŒ¨ë”©

#     # â‘¡ ì´ ê¸¸ì´: ì•”í˜¸í™”í•  ë°ì´í„° ê¸¸ì´ + ì‹œì‘ offset padding
#     total_len = offset_pad + len(data)

#     # â‘¢ íŒŒì¼ ë‹¨ìœ„ íŒ¨ë”©: ëì„ 16ë°”ì´íŠ¸ë¡œ ì •ë ¬í•˜ê¸° ìœ„í•œ íŒ¨ë”© ì‚½ì…
#     aligned_len = (total_len + 0xF) & ~0xF      # 16ì˜ ë°°ìˆ˜ë¡œ ì •ë ¬

#     # â‘£ ì •ë ¬ëœ ë²„í¼ ì¤€ë¹„
#     aligned_buf = bytearray(aligned_len)
#     aligned_buf[offset_pad:offset_pad + len(data)] = data
#     # ë’¤ì— íŒ¨ë”©ëœ ë¶€ë¶„ì€ 0ìœ¼ë¡œ ìœ ì§€ë¨

#     # â‘¤ Camellia ì•”í˜¸í™” (current_offsetë¶€í„° 16ì”© ì¦ê°€)
#     for block in range(0, aligned_len, 16):
#         encryptor.encrypt_block(current_offset, aligned_buf, block)
#         current_offset += 16

#     # â‘¥ ì•”í˜¸í™”ëœ ë°ì´í„° ê¸°ë¡
#     start = offset - offset_pad
#     end = start + aligned_len

#     if isinstance(f, bytearray):
#         if len(f) < end:
#             f += bytearray(end - len(f))
#         f[start:end] = aligned_buf
#     else:
#         f.seek(start)
#         f.write(aligned_buf)

#     return len(data)

# # ì•”í˜¸í™” .dat ë¦¬íŒ© ì½”ë“œ
# # í‰ë¬¸ ë¦¬íŒ©ê³¼ ë§ˆì°¬ê°€ì§€ë¡œ ë©”íƒ€ë°ì´í„°.json ì¹´í”¼ í•„ìˆ˜
# # í˜„ì¬ í”¼ì¼ëª… ê¸€ì ì´ìŠˆ ë¬¸ì œë¡œ ì‚¬ìš©ì„ ë¹„ì¶”ì²œ. ì‚¬ìš©í•˜ê³  ì‹¶ë‹¤ë©´ ë¦¬íŒ© ì „ì— íŒŒì¼ëª… ë° í•´ë‹¹ íŒŒì¼ì„ ì‚¬ìš©í•˜ëŠ” ì—°ê³„ íŒŒì¼ë“¤ì„ 20ë°”ì´íŠ¸ ì´í•˜ë¡œ ìˆ˜ì •í•  ê²ƒ.
# # ì•”í˜¸í™” ì ìš© ì„±ê³µì€ í•˜ë‚˜ í‰ë¬¸ ë¦¬íŒ©ê³¼ ë‹¬ë¦¬ ì‹¤í–‰ì´ ì•ˆë˜ëŠ” ë¬¸ì œë¡œ ì£¼ì„ ì²˜ë¦¬í•¨.
# class DatWriter:
#     def __init__(self, entry_list=None, base_dir=None, meta_dict=None, encryptor=None): 
#         if entry_list is None:
#             entry_list = []

#         self.entries = entry_list
#         self.base_dir = base_dir
#         self.output = bytearray()
#         self.plain_data = None
#         self.meta_dict = meta_dict or {}
#         self.encryptor = encryptor 
#         self.write = self.Writer(self)
#         self.save = self.Save(self)
#         self.offset_table_pos = None

#         # âœ… ì˜¤í”„ì…‹ ëŒ€ìƒ: ì‹¤ì œ íŒŒì¼ë§Œ (ë””ë ‰í† ë¦¬/ë£¨íŠ¸ ì œì™¸)
#         self.offset_entries = [
#             e for e in entry_list
#             if not e.get("is_dir", False)
#         ]

#         # âœ… ì¸ë±ìŠ¤ ëŒ€ìƒ: ë£¨íŠ¸ ë””ë ‰í† ë¦¬ ì œì™¸ ì „ì²´ entry
#         self.index_entries = [
#             e for e in entry_list
#             if e.get("is_dir", False) or not e.get("is_dir", False)
#         ]

#         # âœ… ë””ë ‰í† ë¦¬ ëª©ë¡: nameì´ Noneì´ë©´ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¡œ ì·¨ê¸‰
#         self.folders = [
#             e for e in entry_list
#             if e.get("is_dir", False)
#         ]

#         # âœ… name í•„ë“œ ë³´ì • (ëˆ„ë½ëœ ê²½ìš°)
#         for e in self.entries:
#             if "name" not in e or e["name"] is None:
#                 arc = e.get("arc_path") or ""
#                 e["name"] = os.path.basename(arc.rstrip("/"))

        
#     def add_entry(self, arc_path: str, src_path: str, is_dummy: bool = False):
#         entry = {
#             "arc_path": arc_path,
#             "src_path": src_path,
#             "name": os.path.basename(arc_path.rstrip("/")), 
#         }

#         full_path = os.path.normpath(src_path)
#         is_dir = os.path.isdir(full_path)
#         entry["is_dir"] = is_dir

#         # â”€â”€â”€ size / data ì²˜ë¦¬ â”€â”€â”€
#         if is_dir:
#             entry["size"] = None
#             entry["data"] = b""
#             entry["type_val"] = 0x00
#             entry["extension"] = ""
#         elif os.path.isfile(full_path):
#             with open(full_path, "rb") as f:
#                 data = f.read()
#             entry["size"] = len(data)
#             entry["data"] = data
#             entry["offset"] = None
#             entry["type_val"] = 0x10000
#             entry["extension"] = os.path.splitext(arc_path)[-1].lower()
#         else:
#             logging.warning(f"[add_entry] íŒŒì¼ ë˜ëŠ” ë””ë ‰í† ë¦¬ ì•„ë‹˜: {src_path}")
#             return

#         # í›„ì† ì²˜ë¦¬ë¥¼ ìœ„í•œ ë³´ì¡° í•„ë“œ ì´ˆê¸°í™” (index ê´€ë ¨)
#         # entry["entry_index"] = None
#         entry["offset_index"] = None
#         entry["offset"] = None
#         entry["order"] = -1
        
#         # logging.debug(f"[add_entry] ë“±ë¡ë¨: {arc_path} ({src_path}) is_dir={is_dir}")

#         self.entries.append(entry)
    
#     def add_auto(self, input_dir: str, arc_path: str, root_dir: str = None):
#         if root_dir is None:
#             root_dir = input_dir  # ìµœì´ˆ í˜¸ì¶œ ì‹œ root_dir ê³ ì •

#         full_path = os.path.normpath(os.path.join(input_dir, arc_path))
#         rel_arc_path = os.path.relpath(full_path, root_dir).replace("\\", "/")

#         if rel_arc_path in ("", ".", "./"):
#             rel_arc_path = ""

#         # â”€â”€â”€â”€â”€â”€ ë””ë ‰í† ë¦¬ ì²˜ë¦¬ â”€â”€â”€â”€â”€â”€
#         if os.path.isdir(full_path):
#             if not rel_arc_path.endswith("/") and rel_arc_path != "":
#                 rel_arc_path += "/"

#             # âœ… ë£¨íŠ¸ ë””ë ‰í† ë¦¬ëŠ” ë“±ë¡í•˜ì§€ ì•ŠìŒ (arc_path == "")
#             if rel_arc_path != "":
#                 entry = {
#                     "arc_path": rel_arc_path,
#                     "src_path": full_path,
#                     "name": os.path.basename(rel_arc_path.rstrip("/")), 
#                     "is_dir": True,
#                     "type_val": 0,
#                     "size": 0,
#                     "data": b"",
#                     "is_dummy": False,
#                     "entry_index": None,
#                     "offset_index": None,
#                     "offset": None,
#                     "order": -1,
#                     "extension": "",
#                 }
#                 self.entries.append(entry)
#             #     logging.debug(f"[add_auto] ë””ë ‰í† ë¦¬ ë“±ë¡ë¨: {rel_arc_path} ({full_path})")
#             # else:
#             #     logging.debug(f"[add_auto] ë£¨íŠ¸ ë””ë ‰í† ë¦¬ëŠ” ë“±ë¡ ìƒëµ: {full_path}")

#             # ì¬ê·€ì ìœ¼ë¡œ í•˜ìœ„ í•­ëª© ì¶”ê°€
#             for child in sorted(os.listdir(full_path)):
#                 self.add_auto(full_path, child, root_dir=root_dir)

#         # â”€â”€â”€â”€â”€â”€ íŒŒì¼ ì²˜ë¦¬ â”€â”€â”€â”€â”€â”€
#         elif os.path.isfile(full_path):
#             self.add_entry(rel_arc_path, full_path)

#         # â”€â”€â”€â”€â”€â”€ ê·¸ ì™¸ (ì—†ê±°ë‚˜ ì˜ëª»ëœ ê²½ë¡œ) â”€â”€â”€â”€â”€â”€
#         else:
#             logging.warning(f"[add_auto] íŒŒì¼/ë””ë ‰í† ë¦¬ ì—†ìŒ: {full_path}")

#     def sorted_entries(self):
#         entries = list(self.entries)
#         entries.sort(key=lambda e: e["entry_index"] if isinstance(e.get("entry_index"), int) else 99999)
#         return entries
     
#     def finalize_folders(self):
#         @lru_cache(maxsize=None)
#         def normalize_dir(path: str) -> str:
#             path = os.path.normpath(path).replace("\\", "/")
#             if path in ("", ".", "./"):
#                 return ""
#             return path.rstrip("/") + "/"

#         root_dir_name = self.base_dir.rstrip("/\\").split(os.sep)[-1]
#         normalized_root_dir = normalize_dir(root_dir_name)
#         logging.debug(f"[finalize_folders] ì‚­ì œ ëŒ€ìƒ ìµœìƒìœ„ í´ë” ì´ë¦„ (ì •ê·œí™”): '{normalized_root_dir}'")

#         dir_set = set()
#         for entry in self.entries:
#             arc_path = entry.get("arc_path")
#             if not arc_path or (entry.get("is_dir") and not arc_path.strip("/")):
#                 continue
#             folder = normalize_dir(os.path.dirname(arc_path))
#             while folder:
#                 dir_set.add(folder)
#                 parent = normalize_dir(os.path.dirname(folder.rstrip("/")))
#                 if parent == folder or parent == "":
#                     break
#                 folder = parent
#         logging.debug(f"[finalize_folders] ì´ ë””ë ‰í† ë¦¬ ìˆ˜ì§‘ë¨: {len(dir_set)}")

#         has_root = any(
#             e.get("is_dir") and (e.get("arc_path") in (None, "", "./", "/"))
#             for e in self.entries
#         )

#         if not has_root:
#             subdir_count = sum(
#                 1 for e in self.entries if e.get("is_dir") and e.get("arc_path")
#             )
#             self.entries.insert(0, {
#                 "arc_path": None,
#                 "name": None,
#                 "entry_index": 0,
#                 "offset_index": None,
#                 "offset": 0,
#                 "size": subdir_count,
#                 "is_dir": True,
#                 "order": None,
#                 "extension": "",
#                 "src_path": "__root__",
#                 "type_val": 0x00,
#                 "flags": 0x04 if subdir_count > 0 else 0x05,
#                 "data": b"",
#             })

#         seen = set()
#         unique_entries = []
#         for e in self.entries:
#             ident = (e.get("arc_path"), e.get("is_dir", False))
#             if ident not in seen:
#                 seen.add(ident)
#                 unique_entries.append(e)
#             else:
#                 logging.debug(f"[finalize_folders] ì¤‘ë³µ ì œê±°ë¨: {ident}")
#         self.entries = unique_entries

#         child_count = defaultdict(int)
#         for e in self.entries:
#             arc = normalize_dir(e.get("arc_path") or "")
#             parent = normalize_dir(os.path.dirname(arc.rstrip("/")))
#             child_count[parent] += 1

#         self.index_entries = self.entries.copy()

#         def sort_entries_dfs(entries, normalize_dir):
#             entry_map = {
#                 normalize_dir(e.get("arc_path")): e
#                 for e in entries if e.get("arc_path") is not None
#             }
#             children_map = defaultdict(list)
#             for e in entries:
#                 arc = normalize_dir(e.get("arc_path"))
#                 parent = normalize_dir(os.path.dirname(arc.rstrip("/"))) if arc else ""
#                 children_map[parent].append(e)

#             result = []

#             def dfs(current=""):
#                 children = children_map.get(current, [])
#                 dirs = [e for e in children if e.get("is_dir", False)]
#                 files = [e for e in children if not e.get("is_dir", False)]
#                 dirs.sort(key=lambda e: e.get("arc_path"))
#                 files.sort(key=lambda e: e.get("arc_path"))
#                 result.extend(dirs)
#                 result.extend(files)
#                 for d in dirs:
#                     dfs(normalize_dir(d.get("arc_path")))

#             dfs()
#             return result, entry_map

#         # ì •ë ¬ëœ ì—”íŠ¸ë¦¬ë¡œ ë®ì–´ì“°ê¸°
#         sorted_entries, self.index_map = sort_entries_dfs(
#             [e for e in self.index_entries if e.get("entry_index") != 0 and e.get("arc_path") not in (None, "", "./", "/")],
#             normalize_dir
#         )
#         self.index_entries = [e for e in self.entries if e.get("entry_index") == 0] + sorted_entries

#         # type_val, flags, sizeëŠ” ë©”íƒ€ ê¸°ë°˜ìœ¼ë¡œ ë®ì–´ì“°ê¸° (entry_metadata_manager ì‚¬ìš© ì‹œ ë³´ì¥ë¨)
#         for entry in self.index_entries:
#             if entry.get("is_dir", False):
#                 arc_path = normalize_dir(entry.get("arc_path") or "")
#                 entry["size"] = child_count.get(arc_path, 0)
#                 entry["flags"] = 0x04 if entry["size"] > 0 else 0x05
#                 entry["type_val"] = 0x00000
#             else:
#                 # sizeëŠ” ë°˜ë“œì‹œ ë©”íƒ€ì—ì„œ ë³µì‚¬í•œ ê°’ì´ì–´ì•¼ í•¨. ì—¬ê¸°ì„œ len(data)ë¡œ ë®ìœ¼ë©´ ì•ˆ ë¨!
#                 entry.setdefault("type_val", 0x10000)
#                 entry.setdefault("flags", 0x00)

#             logging.debug(f"[DEBUG-finalize] {entry.get('arc_path') or '[root]'} | "
#                         f"is_dir={entry.get('is_dir')} type_val=0x{entry.get('type_val'):05X} "
#                         f"flags=0x{entry.get('flags'):02X} size={entry.get('size')} "
#                         f"offset_index={entry.get('offset_index')}")

#         # offset_entries
#         self.offset_entries = [e for e in self.index_entries if not e.get("is_dir", False)]
#         self.offset_entries.sort(key=lambda e: e.get("entry_index", 0))
#         for i, entry in enumerate(self.offset_entries):
#             entry["offset_index"] = i

#         logging.debug("[finalize_folders] ì™„ë£Œ")

#     class Writer:
#         def __init__(self, outer):
#             self.outer = outer
#             self.entries = outer.entries
#             self.base_dir = outer.base_dir
#             self.ALIGN_FILE_START = 0x1000

#         # í—¤ë” ì‘ì„±
#         def write_header(self):
#             total_entry_count = len(self.outer.entries)
#             offset_entry_count = len([e for e in self.outer.entries if not e.get("is_dir", False)])

#             # ë£¨íŠ¸ ë””ë ‰í† ë¦¬ ìƒì„± ì—¬ë¶€ í™•ì¸
#             has_root = any(
#                 e.get("is_dir") and (e.get("arc_path") is None or e.get("arc_path") == "")
#                 for e in self.outer.entries
#             )

#             dir_root_count = 1 if has_root else 0
#             subdirs = set()
#             for e in self.outer.entries:
#                 if not e.get("is_dir", False):
#                     continue
#                 arc = e.get("arc_path")
#                 if not arc or arc in ("", "./", "/"):
#                     continue
#                 norm = arc.rstrip("/")
#                 if "/" not in norm:
#                     subdirs.add(norm)

#             subdir_count = len(subdirs)

#             mystery_padding = b'\x00' * 8
#             reserved = b'\x00' * 20

#             parts = [
#                 b'LIBP',
#                 struct.pack('<I', total_entry_count),
#                 struct.pack('<I', offset_entry_count),
#                 mystery_padding,
#                 reserved,
#                 struct.pack('<I', dir_root_count),
#                 struct.pack('<I', subdir_count),
#             ]

#             header = b''.join(parts)
#             assert len(header) == 0x30, f"í—¤ë” ê¸¸ì´ ë¶ˆì¼ì¹˜: {len(header)}"

#             # âœ… ì•”í˜¸í™” ì ìš© (offset = 0)
#             if self.outer.encryptor:
#                 encrypted = bytearray()
#                 write_encrypted(encrypted, self.outer.encryptor, 0, header)
#                 self.outer.output += encrypted
#             else:
#                 self.outer.output += header

#             logging.info(f"[write] í—¤ë” ì‘ì„± ì™„ë£Œ (ì´ {total_entry_count}, íŒŒì¼ {offset_entry_count}, ë””ë ‰í† ë¦¬ {subdir_count})")
            
#         # íŒŒì¼ ì¸ë±ìŠ¤ í…Œì´ë¸” ì‘ì„±
#         # ë£¨íŠ¸ ë””ë ‰í† ë¦¬ëŠ” ì œì™¸. jsonì˜ entry_index ìˆœë²ˆ ë°˜ì˜, ë””ë ‰í† ë¦¬ ì •ë³´ë˜í•œ json ë°˜ì˜.
#         # 20ë°”ì´íŠ¸ í•œê³„ë¡œ 21ë°”ì´íŠ¸ê°€ ë„˜ì–´ê°€ëŠ” íŒŒì¼ëª…ì€ í—¥ìŠ¤ ì—ë””í„°ë¡œ ìˆ˜ì • í•„ìˆ˜. (íŒŒì¼ëª…ì„ ìˆ˜ì •í•˜ëŠ” ë°©ë²•ë„ ìˆìœ¼ë‚˜ ì—°ê³„ íŒŒì¼ë“¤ë„ ê°™ì´ ìˆ˜ì •í•´ì•¼ í•¨.)
#         # ìˆœì„œëŠ” ê° .datë§ˆë‹¤ ë‹¤ë¦„. 
#         def write_index_table(self):
#             def encode_name(name: str) -> bytes:
#                 raw = name.encode("cp932", "ignore").split(b'\x00')[0][:20]
#                 return raw.ljust(20, b'\x00')

#             index_table = bytearray()
#             count = 0

#             entries = sorted(
#                 self.outer.index_entries,
#                 key=lambda e: e.get("entry_index", -1) if isinstance(e.get("entry_index"), int) else 99999
#             )
#             for i, e in enumerate(entries):
#                 logging.debug(f"[write_index_table] #{i} {e.get('arc_path')} (entry_index={e.get('entry_index')})")

#             for e in entries:
#                 arc_path = e.get("arc_path") or ""
#                 is_dir = bool(e.get("is_dir", False))

#                 if is_dir and arc_path.strip("/").strip() == "":
#                     logging.debug(f"[write_index_table] ë£¨íŠ¸ ë””ë ‰í† ë¦¬ ì œì™¸: {e}")
#                     continue

#                 arc_name = os.path.basename(arc_path.rstrip("/"))
#                 name_bytes = encode_name(arc_name)
#                 assert len(name_bytes) == 20, f"name_bytes ê¸¸ì´ ì˜¤ë¥˜: {arc_name} â†’ {len(name_bytes)}"

#                 type_val = e["type_val"]
#                 size = e["size"]
#                 entry_bytes = bytearray()
#                 entry_bytes += name_bytes                          # 0x00â€“0x13
#                 entry_bytes += struct.pack("<I", type_val)         # 0x14â€“0x17

#                 # âœ… 0x18â€“0x1B ìœ„ì¹˜ì— ë„£ì„ ê°’
#                 raw_0x18 = None

#                 if is_dir:
#                     tail_raw_hex = e.get("index_tail_raw")
#                     assert tail_raw_hex, f"ë””ë ‰í† ë¦¬ì¸ë° index_tail_raw ì—†ìŒ: {arc_path}"
#                     raw_0x18 = bytes.fromhex(tail_raw_hex)
#                 else:
#                     raw_0x18 = struct.pack("<I", e["offset_index"])

#                 entry_bytes += raw_0x18                            # 0x18â€“0x1B
#                 entry_bytes += struct.pack("<I", size)             # 0x1Câ€“0x1F

#                 assert len(entry_bytes) == 0x20, f"entry í¬ê¸° ì˜¤ë¥˜: {arc_path}"
#                 index_table += entry_bytes
#                 count += 1

#             # âœ… index_table ì•”í˜¸í™” ì ìš©
#             if self.outer.encryptor:
#                 logging.debug(f"[encrypt] ì¸ë±ìŠ¤ í…Œì´ë¸” ì•”í˜¸í™” ì‹œì‘ (size: {len(index_table)})")
#                 write_encrypted(self.outer.output, self.outer.encryptor, len(self.outer.output), index_table)
#             else:
#                 self.outer.output += index_table

#             logging.info(f"[write_index_table] ì¸ë±ìŠ¤ í…Œì´ë¸” ì‘ì„± ì™„ë£Œ (ì—”íŠ¸ë¦¬ ìˆ˜: {count})")
        
#         # ë² ì´ìŠ¤ ì˜¤í”„ì…‹ ê³„ì‚° (íŒŒì¼ ë°ì´í„° ì‘ì„±ê³¼ ì—°ê³„)
#         def calculate_base_offset(self):
#             ALIGN_BASE = 0x1000  # âœ… íŒŒì¼ ë°ì´í„° ì •ë ¬ ë‹¨ìœ„

#             entry_count = len(self.outer.entries)
#             file_count = len([e for e in self.outer.entries if not e.get("is_dir", False)])

#             index_size = entry_count * 0x20
#             offset_table_size = file_count * 4

#             raw_base = 0x10 + index_size + offset_table_size
#             self.outer.base_offset = (raw_base + ALIGN_BASE - 1) & ~(ALIGN_BASE - 1)
            
#         # ì˜¤í”„ì…‹(ì˜¤í”„ì…‹ í…Œì´ë¸”, ë² ì´ìŠ¤ ì˜¤í”„ì…‹) ê³„ì‚°ê³¼ ì •ë ¬
#         def prepare_offsets(self):
#             all_entries = self.outer.offset_entries
#             offset_entries = [e for e in all_entries if not e.get("is_dir", False)]
#             self.offset_table = [0] * len(offset_entries)

#             for entry in offset_entries:
#                 write_offset = entry.get("write_offset")
#                 if write_offset is None:
#                     raise ValueError(f"write_offset ëˆ„ë½: {entry.get('arc_path')}")

#                 offset_val = (write_offset - self.outer.base_offset) >> 10
#                 self.offset_table[entry["offset_index"]] = offset_val

#             logging.info(f"[prepare_offsets] ì˜¤í”„ì…‹ ê³„ì‚° ì™„ë£Œ (ì´ íŒŒì¼ ìˆ˜: {len(offset_entries)})")
            
#         # ì˜¤í”„ì…‹ í…Œì´ë¸” ì‘ì„± (prepare_offsetsì—ì„œ ë°ì´í„°ë¥¼ ë°›ìŒ)
#         def write_offset_table(self):
#             offset_pos = 0x10 + 0x20 * len(self.outer.entries)

#             table_bytes = bytearray()
#             for val in self.offset_table:
#                 table_bytes += struct.pack("<I", val)

#             logging.info(f"[write_offset_table] ì˜¤í”„ì…‹ í…Œì´ë¸” ì‘ì„± ì™„ë£Œ (ì´ {len(self.offset_table)}ê°œ)")

#             # ì•”í˜¸í™” ì „ìš© â†’ ë¬´ì¡°ê±´ encryptor ì¡´ì¬
#             write_encrypted(self.outer.output, self.outer.encryptor, offset_pos, table_bytes)

#         # íŒŒì¼ ë°ì´í„° ì‘ì„± 
#         # íŒŒì¼ ë°ì´í„° ìˆœì„œê°€ ì—‰ë§ì´ê¸°ì— ë©”íƒ€ë°ì´í„°.json ì°¸ì¡° ì¹´í”¼ í•„ìˆ˜.
#         def write_data(self):
#             def align_inner(val):
#                 return (val + 0x3FF) & ~0x3FF

#             def align_block(val):
#                 return (val + 0xFFF) & ~0xFFF

#             entries = sorted(
#                 [e for e in self.outer.entries if not e.get("is_dir", False)],
#                 key=lambda e: e.get("order", -1)
#             )

#             cursor = self.outer.base_offset
#             f = self.outer.output
#             encryptor = self.outer.encryptor  # ë¬´ì¡°ê±´ ì•”í˜¸í™” ê°ì²´ë§Œ ì”€

#             if encryptor is None:
#                 raise RuntimeError("[write_data] encryptor ì—†ìŒ. ì•”í˜¸í™” ë¦¬íŒ© ì „ìš© ì½”ë“œì—ì„œ encryptorê°€ ë°˜ë“œì‹œ í•„ìš”í•©ë‹ˆë‹¤.")

#             for idx, entry in enumerate(entries):
#                 arc_path = entry["arc_path"]
#                 size = int(entry["size"], 16) if isinstance(entry["size"], str) else entry["size"]
#                 data = entry["data"]

#                 offset = align_inner(cursor)
#                 if (offset // 0x1000) != (cursor // 0x1000):
#                     offset = align_block(cursor)

#                 end_offset = offset + size
#                 entry["write_offset"] = offset

#                 if len(f) < end_offset:
#                     f += bytearray(end_offset - len(f))

#                 # ğŸ” ë¬´ì¡°ê±´ ì•”í˜¸í™” write (í‰ë¬¸ ì ˆëŒ€ ì—†ìŒ)
#                 write_encrypted(f, encryptor, offset, data)

#                 if getattr(self.outer, "debug", True):
#                     logging.debug(
#                         f"[write_data] #{idx:04d} | {arc_path}"
#                         f"\n    write_offset=0x{offset:X}, size=0x{size:X}, end=0x{end_offset:X}"
#                         f"\n    encrypt=YES"
#                         f"\n    new_output_len=0x{len(f):X}"
#                     )

#                 cursor = end_offset

#     # ë¦¬íŒ© í›„ .dat ì €ì¥
#     class Save:
#         def __init__(self, outer):
#             self.outer = outer

#         def to_file(self, path: str):
#             with open(path, "wb") as f:
#                 f.write(self.outer.output)
#                 print(f"[ì™„ë£Œ] ì•”í˜¸í™” DAT ë¦¬íŒ© â†’ {path}")